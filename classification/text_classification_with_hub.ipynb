{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 使用 Keras 和Tensorflow Hub 对电影评论进行文本分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.5.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n",
      "tf_datasets version:  4.4.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"tf_datasets version: \", tfds.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 将训练集分割成 60% 和 40%，从而最终我们将得到 15,000 个训练样本\n",
    "# 10,000 个验证样本以及 25,000 个测试样本。\n",
    "train_data, validation_data, test_data = tfds.load(\n",
    "    name=\"imdb_reviews\",\n",
    "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
    "    as_supervised=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-01 04:16:51.752115: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 0, 0, 1, 1, 1, 0, 0, 0, 0])>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 代表消极评论，1 代表积极评论\n",
    "train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\n",
    "\n",
    "train_examples_batch\n",
    "\n",
    "train_labels_batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-01 04:16:51.794912: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-08-01 04:16:51.811703: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3, 20), dtype=float32, numpy=\narray([[ 1.765786  , -3.882232  ,  3.9134233 , -1.5557289 , -3.3362343 ,\n        -1.7357955 , -1.9954445 ,  1.2989551 ,  5.081598  , -1.1041286 ,\n        -2.0503852 , -0.72675157, -0.65675956,  0.24436149, -3.7208383 ,\n         2.0954835 ,  2.2969332 , -2.0689783 , -2.9489717 , -1.1315987 ],\n       [ 1.8804485 , -2.5852382 ,  3.4066997 ,  1.0982676 , -4.056685  ,\n        -4.891284  , -2.785554  ,  1.3874227 ,  3.8476458 , -0.9256538 ,\n        -1.896706  ,  1.2113281 ,  0.11474707,  0.76209456, -4.8791065 ,\n         2.906149  ,  4.7087674 , -2.3652055 , -3.5015898 , -1.6390051 ],\n       [ 0.71152234, -0.6353217 ,  1.7385626 , -1.1168286 , -0.5451594 ,\n        -1.1808156 ,  0.09504455,  1.4653089 ,  0.66059524,  0.79308075,\n        -2.2268345 ,  0.07446612, -1.4075904 , -0.70645386, -1.907037  ,\n         1.4419787 ,  1.9551861 , -0.42660055, -2.8022065 ,  0.43727064]],\n      dtype=float32)>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = \"https://hub.tensorflow.google.cn/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[],\n",
    "                           dtype=tf.string, trainable=True)\n",
    "hub_layer(train_examples_batch[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_1 (KerasLayer)   (None, 20)                400020    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 400,373\n",
      "Trainable params: 400,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation Adam/Adam/update/Unique: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nAssignSubVariableOp: GPU CPU \nRealDiv: GPU CPU \nResourceGather: GPU CPU \nAddV2: GPU CPU \nSqrt: GPU CPU \nUnique: CPU \nResourceScatterAdd: GPU CPU \nUnsortedSegmentSum: CPU \nAssignVariableOp: GPU CPU \nReadVariableOp: GPU CPU \nNoOp: GPU CPU \nMul: GPU CPU \nShape: GPU CPU \nIdentity: GPU CPU \nStridedSlice: GPU CPU \n_Arg: GPU CPU \nConst: GPU CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  sequential_1_keras_layer_1_1354 (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  adam_adam_update_readvariableop_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  adam_adam_update_readvariableop_2_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/Unique (Unique) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/Shape (Shape) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice/stack (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice/stack_1 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice/stack_2 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice (StridedSlice) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/UnsortedSegmentSum (UnsortedSegmentSum) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/mul (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp (ReadVariableOp) \n  Adam/Adam/update/mul_1 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/AssignVariableOp (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ResourceScatterAdd (ResourceScatterAdd) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp_1 (ReadVariableOp) \n  Adam/Adam/update/mul_2 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/mul_3 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp_2 (ReadVariableOp) \n  Adam/Adam/update/mul_4 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/AssignVariableOp_1 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ResourceScatterAdd_1 (ResourceScatterAdd) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp_3 (ReadVariableOp) \n  Adam/Adam/update/Sqrt (Sqrt) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/mul_5 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/add (AddV2) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/truediv (RealDiv) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/AssignSubVariableOp (AssignSubVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/group_deps/NoOp (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/group_deps/NoOp_1 (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/group_deps (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Func/sequential_1/keras_layer_1/StatefulPartitionedCall/input/_3 (Identity) /job:localhost/replica:0/task:0/device:GPU:0\n  sequential_1/keras_layer_1/StatefulPartitionedCall/StatefulPartitionedCall/embedding_lookup_sparse/embedding_lookup/Read/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:CPU:0\n  sequential_1/keras_layer_1/StatefulPartitionedCall/StatefulPartitionedCall/embedding_lookup_sparse/embedding_lookup (ResourceGather) /job:localhost/replica:0/task:0/device:CPU:0\n  sequential_1/keras_layer_1/StatefulPartitionedCall/StatefulPartitionedCall/embedding_lookup_sparse/embedding_lookup/Identity_1 (Identity) /job:localhost/replica:0/task:0/device:CPU:0\n  Func/sequential_1/keras_layer_1/StatefulPartitionedCall/StatefulPartitionedCall/input/_22 (Identity) /job:localhost/replica:0/task:0/device:GPU:0\n\nOp: Unique\nNode attrs: T=DT_INT64, out_idx=DT_INT32, _class=[\"loc:@sequential_1/keras_layer_1/1354\"]\nRegistered kernels:\n  device='CPU'; T in [DT_UINT64]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_UINT64]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_INT64]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_INT64]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_UINT32]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_UINT32]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_UINT16]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_UINT16]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_INT16]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_INT16]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_UINT8]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_UINT8]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_INT8]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_INT8]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_INT32]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_INT32]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_HALF]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_HALF]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_BFLOAT16]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_BFLOAT16]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_FLOAT]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_FLOAT]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_DOUBLE]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_DOUBLE]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_STRING]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_STRING]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_BOOL]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_BOOL]; out_idx in [DT_INT64]\n\n\t [[{{node Adam/Adam/update/Unique}}]] [Op:__inference_train_function_1605]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/xf/nrz9x0bx0kd7fl28_vnb7fdw0000gn/T/ipykernel_7143/2139120784.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m               metrics=['accuracy'])\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m model.fit(train_data.shuffle(10000).batch(512),\n\u001B[0m\u001B[1;32m      6\u001B[0m                     \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m                     \u001B[0mvalidation_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvalidation_data\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m512\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1181\u001B[0m                 _r=1):\n\u001B[1;32m   1182\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1183\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1184\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1185\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    887\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    891\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    948\u001B[0m         \u001B[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    949\u001B[0m         \u001B[0;31m# stateless function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 950\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    951\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    952\u001B[0m       \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfiltered_flat_args\u001B[0m \u001B[0;34m=\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3021\u001B[0m       (graph_function,\n\u001B[1;32m   3022\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m-> 3023\u001B[0;31m     return graph_function._call_flat(\n\u001B[0m\u001B[1;32m   3024\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[1;32m   3025\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1958\u001B[0m         and executing_eagerly):\n\u001B[1;32m   1959\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1960\u001B[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[1;32m   1961\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[1;32m   1962\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    589\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    590\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 591\u001B[0;31m           outputs = execute.execute(\n\u001B[0m\u001B[1;32m    592\u001B[0m               \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    593\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     57\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 59\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     61\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: Cannot assign a device for operation Adam/Adam/update/Unique: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nAssignSubVariableOp: GPU CPU \nRealDiv: GPU CPU \nResourceGather: GPU CPU \nAddV2: GPU CPU \nSqrt: GPU CPU \nUnique: CPU \nResourceScatterAdd: GPU CPU \nUnsortedSegmentSum: CPU \nAssignVariableOp: GPU CPU \nReadVariableOp: GPU CPU \nNoOp: GPU CPU \nMul: GPU CPU \nShape: GPU CPU \nIdentity: GPU CPU \nStridedSlice: GPU CPU \n_Arg: GPU CPU \nConst: GPU CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  sequential_1_keras_layer_1_1354 (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  adam_adam_update_readvariableop_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  adam_adam_update_readvariableop_2_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/Unique (Unique) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/Shape (Shape) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice/stack (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice/stack_1 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice/stack_2 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice (StridedSlice) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/UnsortedSegmentSum (UnsortedSegmentSum) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/mul (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp (ReadVariableOp) \n  Adam/Adam/update/mul_1 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/AssignVariableOp (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ResourceScatterAdd (ResourceScatterAdd) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp_1 (ReadVariableOp) \n  Adam/Adam/update/mul_2 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/mul_3 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp_2 (ReadVariableOp) \n  Adam/Adam/update/mul_4 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/AssignVariableOp_1 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ResourceScatterAdd_1 (ResourceScatterAdd) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp_3 (ReadVariableOp) \n  Adam/Adam/update/Sqrt (Sqrt) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/mul_5 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/add (AddV2) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/truediv (RealDiv) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/AssignSubVariableOp (AssignSubVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/group_deps/NoOp (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/group_deps/NoOp_1 (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/group_deps (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Func/sequential_1/keras_layer_1/StatefulPartitionedCall/input/_3 (Identity) /job:localhost/replica:0/task:0/device:GPU:0\n  sequential_1/keras_layer_1/StatefulPartitionedCall/StatefulPartitionedCall/embedding_lookup_sparse/embedding_lookup/Read/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:CPU:0\n  sequential_1/keras_layer_1/StatefulPartitionedCall/StatefulPartitionedCall/embedding_lookup_sparse/embedding_lookup (ResourceGather) /job:localhost/replica:0/task:0/device:CPU:0\n  sequential_1/keras_layer_1/StatefulPartitionedCall/StatefulPartitionedCall/embedding_lookup_sparse/embedding_lookup/Identity_1 (Identity) /job:localhost/replica:0/task:0/device:CPU:0\n  Func/sequential_1/keras_layer_1/StatefulPartitionedCall/StatefulPartitionedCall/input/_22 (Identity) /job:localhost/replica:0/task:0/device:GPU:0\n\nOp: Unique\nNode attrs: T=DT_INT64, out_idx=DT_INT32, _class=[\"loc:@sequential_1/keras_layer_1/1354\"]\nRegistered kernels:\n  device='CPU'; T in [DT_UINT64]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_UINT64]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_INT64]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_INT64]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_UINT32]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_UINT32]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_UINT16]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_UINT16]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_INT16]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_INT16]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_UINT8]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_UINT8]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_INT8]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_INT8]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_INT32]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_INT32]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_HALF]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_HALF]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_BFLOAT16]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_BFLOAT16]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_FLOAT]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_FLOAT]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_DOUBLE]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_DOUBLE]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_STRING]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_STRING]; out_idx in [DT_INT64]\n  device='CPU'; T in [DT_BOOL]; out_idx in [DT_INT32]\n  device='CPU'; T in [DT_BOOL]; out_idx in [DT_INT64]\n\n\t [[{{node Adam/Adam/update/Unique}}]] [Op:__inference_train_function_1605]"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data.shuffle(10000).batch(512),\n",
    "                    epochs=20,\n",
    "                    validation_data=validation_data.batch(512),\n",
    "                    verbose=1)\n",
    "\n",
    "model.evaluate(test_data.batch(512), verbose=2)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}